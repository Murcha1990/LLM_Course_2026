{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Murcha1990/LLM_Course_2026/blob/main/Lection1_NLPBasics/LLM_Course_Sem1_IntroNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbHlWheTvTYi"
      },
      "source": [
        "# Семинар 1: обработка текстовых данных\n",
        "\n",
        "## Вступление\n",
        "Многие практические задачи так или иначе могут вовлекать в себя работу с текстовыми данными, например:\n",
        "\n",
        "- классификация текстов\n",
        "    - анализ тональности (например, позитивный/негативный отзыв)\n",
        "    - фильтрация спама\n",
        "    - по теме или жанру\n",
        "- машинный перевод\n",
        "- распознавание и синтез речи\n",
        "- извлечение информации\n",
        "    - именованные сущности (например, извлечение имен, локаций, названий организаций)\n",
        "    - извлечение фактов и событий\n",
        "- кластеризация текстов\n",
        "- оптическое распознавание символов\n",
        "- проверка правописания\n",
        "- вопросно-ответные системы, информационный поиск\n",
        "- суммаризация текстов\n",
        "- генерация текстов\n",
        "\n",
        "В целом, алгоритм работы с текстовыми данными можно разбить на такие шаги:\n",
        "\n",
        "- предобработка сырых данных\n",
        "- токенизация (создание словаря)\n",
        "- обработка словаря (удаление стоп-слов и пунктуации)\n",
        "- обработка токенов (лемматизация / стемминг)\n",
        "- векторизация текста (bag of words, TF-IDF, etc)\n",
        "\n",
        "Сегодня мы познакомимся с основами работы с текстовыми данными: рассмотрим некоторые методы предобработки и простейшие алгоритмы векторизации.\n",
        "\n",
        "### План семинара\n",
        "1. Токенизация\n",
        "2. Стоп-слова и пунктуация\n",
        "3. Лемматизация и стемминг\n",
        "4. Bag-of-words и TD-IDF\n",
        "5. Решение задачи с текстовыми данными\n",
        "6. Регулярные выражения\n",
        "7. Немножко про категориальные признаки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTYWd8k5vTYk"
      },
      "source": [
        "## 1. Токенизация\n",
        "\n",
        "Токенизировать — значит, поделить текст на слова, или *токены*. Самый наивный способ токенизировать текст — разделить на слова по пробелам с помощью `split`. Но `split` упускает очень много всего, например, не отделяет пунктуацию от слов. Кроме этого есть ещё много менее тривиальных проблем, которые мы обсудим по ходу семинара, поэтому на практике всегда используют готовые токенизаторы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.367394Z",
          "start_time": "2023-04-18T16:50:56.706955Z"
        },
        "id": "7wYTyUXsvTYk"
      },
      "outputs": [],
      "source": [
        "# !pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.369338Z",
          "start_time": "2023-04-18T16:50:56.707864Z"
        },
        "id": "0hCRd91OvTYl"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.388966Z",
          "start_time": "2023-04-18T16:50:57.270155Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giW4EnzJbR2z",
        "outputId": "d423e7a6-41f2-4494-ac1f-347777d58746"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "nltk.download(\"punkt\", quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.404335Z",
          "start_time": "2023-04-18T16:50:57.388538Z"
        },
        "id": "BnwtbxVSvTYl"
      },
      "outputs": [],
      "source": [
        "example = \"Но не каждый хочет что-то исправлять:(\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.404687Z",
          "start_time": "2023-04-18T16:50:57.391837Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2GQ7QsjvTYm",
        "outputId": "8cd3ab57-41cb-4c0f-9874-2cbd95468989"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Но', 'не', 'каждый', 'хочет', 'что-то', 'исправлять:(']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "# c помощью split()\n",
        "example.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.404799Z",
          "start_time": "2023-04-18T16:50:57.394339Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA0DyFIDvTYn",
        "outputId": "5d440940-b92f-48fc-cfa3-4f695611972f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Но', 'не', 'каждый', 'хочет', 'что-то', 'исправлять', ':', '(']"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "# c помощью токенизатора\n",
        "word_tokenize(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ7uHEJUvTYo"
      },
      "source": [
        "В nltk вообще есть довольно много токенизаторов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.404913Z",
          "start_time": "2023-04-18T16:50:57.400438Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fnNryNkvTYo",
        "outputId": "4033f562-8896-43a7-a2dd-ed147daa01df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BlanklineTokenizer',\n",
              " 'LegalitySyllableTokenizer',\n",
              " 'LineTokenizer',\n",
              " 'MWETokenizer',\n",
              " 'NLTKWordTokenizer',\n",
              " 'PunktSentenceTokenizer',\n",
              " 'RegexpTokenizer',\n",
              " 'ReppTokenizer',\n",
              " 'SExprTokenizer',\n",
              " 'SpaceTokenizer',\n",
              " 'StanfordSegmenter',\n",
              " 'SyllableTokenizer',\n",
              " 'TabTokenizer',\n",
              " 'TextTilingTokenizer',\n",
              " 'ToktokTokenizer',\n",
              " 'TreebankWordDetokenizer']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "from nltk import tokenize\n",
        "\n",
        "dir(tokenize)[:16]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cs6tdtHvTYp"
      },
      "source": [
        "Можно получить индексы начала и конца каждого токена:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.405149Z",
          "start_time": "2023-04-18T16:50:57.403084Z"
        },
        "id": "v3kOepXRvTYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "096a05f7-67cb-431b-b428-f3e179316d71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 2), (3, 5), (6, 12), (13, 18), (19, 25), (26, 38)]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "wh_tok = tokenize.WhitespaceTokenizer()\n",
        "list(wh_tok.span_tokenize(example))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeMsc1yVvTYp"
      },
      "source": [
        "Некторые токенизаторы ведут себя специфично:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.413500Z",
          "start_time": "2023-04-18T16:50:57.405960Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5diW1OKkvTYq",
        "outputId": "0c57ed16-5f6c-43e8-a1df-0ae40aed63dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['expectation-maximization', 'algorithm']"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "tokenize.TreebankWordTokenizer().tokenize(\"expectation-maximization algorithm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4Jte9_YvTYq"
      },
      "source": [
        "Для некоторых задач это может быть полезно.\n",
        "\n",
        "А некоторые предназначены вообще не для текста на естественном языке:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.413696Z",
          "start_time": "2023-04-18T16:50:57.408712Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC4pjzzWvTYr",
        "outputId": "faa25073-6c14-46c0-cc77-3999d805b4c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['(a (b c))', 'd', 'e', '(f)']"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "tokenize.SExprTokenizer().tokenize(\"(a (b c)) d e (f)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTLQY6ndwP9u"
      },
      "source": [
        "Есть токенизатор, который может быть полезен для работы с твитами или сообщениями из соц. сетей. Он сохранит смайлики, хештеги и т.п."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.421227Z",
          "start_time": "2023-04-18T16:50:57.410680Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xioD_3G2vTYs",
        "outputId": "ed6825ce-d951-4b1f-fdc6-1c3e7579118e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Но', 'не', 'каждый', 'хочет', 'что-то', 'исправлять', ':(']"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "tw = TweetTokenizer()\n",
        "tw.tokenize(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc1OYy0tvTYt"
      },
      "source": [
        "## 2. Стоп-слова и пунктуация\n",
        "\n",
        "*Стоп-слова* — это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.421378Z",
          "start_time": "2023-04-18T16:50:57.416461Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2F7i9CEvTYt",
        "outputId": "005fb879-8ffb-4d95-d16d-8f0cbb3e62b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "nltk.download(\"stopwords\", quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.425601Z",
          "start_time": "2023-04-18T16:50:57.419634Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8NdjFCYvTYt",
        "outputId": "185d7905-1711-416d-93a4-325a472acf5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "print(stopwords.words(\"russian\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.502816Z",
          "start_time": "2023-04-18T16:50:57.424371Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qe79BdbbR25",
        "outputId": "ce7f001e-7ceb-4464-bb1e-88ce4a999ab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ],
      "source": [
        "print(stopwords.words(\"english\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.503520Z",
          "start_time": "2023-04-18T16:50:57.426937Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "2DehgAP3vTYu",
        "outputId": "8851cb52-c8d4-4f66-c66a-d327fe2ac13c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from string import punctuation\n",
        "\n",
        "punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.503604Z",
          "start_time": "2023-04-18T16:50:57.429475Z"
        },
        "id": "gLzygOQ6vTYv"
      },
      "outputs": [],
      "source": [
        "noise = stopwords.words(\"russian\") + list(punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SEdeiiPvTYv"
      },
      "source": [
        "## 3. Лемматизация и стемминг\n",
        "### 3.1 Лемматизация\n",
        "\n",
        "[**Лемматизация**](https://en.wikipedia.org/wiki/Lemmatisation) — процесс приведения слова к его нормальной форме (**лемме**):\n",
        "- для существительных — именительный падеж, единственное число;\n",
        "- для прилагательных — именительный падеж, единственное число, мужской род;\n",
        "- для глаголов, причастий, деепричастий — глагол в инфинитиве.\n",
        "\n",
        "Например, токены «пью», «пил», «пьет» перейдут в «пить». Почему это хорошо?\n",
        "* Во-первых, мы хотим рассматривать как отдельный признак каждое *слово*, а не каждую его отдельную форму.\n",
        "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лемматизации выкидываем мы только её.\n",
        "\n",
        "Для русского есть два хороших лемматизатора: `mystem` и `pymorphy`.\n",
        "\n",
        "#### [Mystem](https://tech.yandex.ru/mystem/)\n",
        "\n",
        "Mystem — это пример популярной библиотеки для лемматизации. Как с ним работать:\n",
        "* скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
        "* использовать обёртку для питона [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) (она медленнее, но удобнее в использовании)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.503677Z",
          "start_time": "2023-04-18T16:50:57.431943Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM5dc5MPvTYw",
        "outputId": "ee31507a-f17a-4055-99ea-02fc9375ed82",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymystem3 in /usr/local/lib/python3.9/dist-packages (0.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from pymystem3) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->pymystem3) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->pymystem3) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->pymystem3) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->pymystem3) (1.26.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymystem3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.503718Z",
          "start_time": "2023-04-18T16:50:57.433253Z"
        },
        "id": "60Q4xp6yvTYw"
      },
      "outputs": [],
      "source": [
        "from pymystem3 import Mystem\n",
        "\n",
        "mystem_analyzer = Mystem()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al294srlvTYx"
      },
      "source": [
        "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
        "* mystem_bin — путь к `mystem`, если их несколько\n",
        "* grammar_info — нужна ли грамматическая информация или только леммы (по умолчанию нужна)\n",
        "* disambiguation — нужно ли снятие [омонимии](https://ru.wikipedia.org/wiki/%D0%9E%D0%BC%D0%BE%D0%BD%D0%B8%D0%BC%D1%8B) - дизамбигуация (по умолчанию нужна)\n",
        "* entire_input — нужно ли сохранять в выводе все (пробелы, например), или можно выкинуть (по умолчанию оставляется все)\n",
        "\n",
        "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
        "\n",
        "Можно просто лемматизировать текст:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.954209Z",
          "start_time": "2023-04-18T16:50:57.436430Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Oc4plDGvTYx",
        "outputId": "2a6a30c3-f92b-49c2-d837-51b6115af01b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['но', ' ', 'не', ' ', 'каждый', ' ', 'хотеть', ' ', 'что-то', ' ', 'исправлять', ':(\\n']\n"
          ]
        }
      ],
      "source": [
        "print(mystem_analyzer.lemmatize(example))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mX1O12xvTYy"
      },
      "source": [
        "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
        "Это модуль на питоне, довольно быстрый и с кучей функций."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.956279Z",
          "start_time": "2023-04-18T16:50:57.953848Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7-NcH9ivTYy",
        "outputId": "192edf33-f079-40a2-b474-99cf0a05ccb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting docopt>=0.6\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=643ff48508ded0865100006ffa9c84a39e88eeb198978e707adbbb6e1eba75de\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymorphy2-dicts\n",
            "  Downloading pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymorphy2-dicts\n",
            "Successfully installed pymorphy2-dicts-2.4.393442.3710985\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: DAWG-Python in /usr/local/lib/python3.9/dist-packages (0.7.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymorphy2\n",
        "!pip install pymorphy2-dicts\n",
        "!pip install DAWG-Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:57.963124Z",
          "start_time": "2023-04-18T16:50:57.956363Z"
        },
        "id": "pjReTCR_bR27"
      },
      "outputs": [],
      "source": [
        "from pymorphy2 import MorphAnalyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.019760Z",
          "start_time": "2023-04-18T16:50:57.963923Z"
        },
        "id": "jnL4uv6JvTYz"
      },
      "outputs": [],
      "source": [
        "pymorphy2_analyzer = MorphAnalyzer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIe3ssarvTYz"
      },
      "source": [
        "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение, то он его просто не лемматизирует, т.к. не понимает.\n",
        "\n",
        "Метод MorphAnalyzer.parse() принимает слово и возвращает все возможные его разборы.\n",
        "\n",
        "У каждого разбора есть тег. Тег — это набор граммем, характеризующих данное слово. Например, тег 'VERB,perf,intr plur,past,indc' означает, что слово — глагол (VERB) совершенного вида (perf), непереходный (intr), множественного числа (plur), прошедшего времени (past), изъявительного наклонения (indc).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.024019Z",
          "start_time": "2023-04-18T16:50:58.020616Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ztv5u7gvTY0",
        "outputId": "11c1957a-9d4e-43a5-efc3-50393138215a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parse(word='хочет', tag=OpencorporaTag('VERB,impf,tran sing,3per,pres,indc'), normal_form='хотеть', score=1.0, methods_stack=((DictionaryAnalyzer(), 'хочет', 3136, 5),))]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "ana = pymorphy2_analyzer.parse(\"хочет\")\n",
        "ana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.027260Z",
          "start_time": "2023-04-18T16:50:58.023109Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "9NBnUjhfvTY2",
        "outputId": "1caec0b7-3d1c-467f-f029-2634d91cd9d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'хотеть'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "ana[0].normal_form"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY0CeomBvTY3"
      },
      "source": [
        "### mystem vs. pymorphy\n",
        "\n",
        "1) *Надеемся, что вы пользуетесь линуксом или маком* — mystem работает невероятно медленно под windows на больших текстах\n",
        "\n",
        "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.028266Z",
          "start_time": "2023-04-18T16:50:58.025883Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZHNWM8MvTY3",
        "outputId": "3b53ab79-8a8a-4cf9-b237-ece730ef7d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'analysis': [{'lex': 'сорок', 'wt': 0.8710292664, 'gr': 'NUM=(пр|дат|род|твор)'}], 'text': 'сорока'}\n",
            "{'analysis': [{'lex': 'сорока', 'wt': 0.1210970041, 'gr': 'S,жен,од=им,ед'}], 'text': 'Сорока'}\n"
          ]
        }
      ],
      "source": [
        "homonym1 = \"За время обучения я прослушал больше сорока курсов.\"\n",
        "homonym2 = \"Сорока своровала блестящее украшение со стола.\"\n",
        "\n",
        "# корректно определил части речи\n",
        "# NUM — числительное\n",
        "# S — существительное\n",
        "print(mystem_analyzer.analyze(homonym1)[-5])\n",
        "print(mystem_analyzer.analyze(homonym2)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4ifiT5avTY4"
      },
      "source": [
        "### 3.2 Стемминг\n",
        "\n",
        "В отличие от лемматизации, при применении стемминга у всех слов отбрасываются аффиксы (окончания и суффиксы), что необязательно приводит слова к формам, существующим в рассматриваемом языке. [**Snowball**](http://snowball.tartarus.org/) — фрэймворк для написания алгоритмов стемминга. Алгоритмы стемминга отличаются для разных языков и используют знания о конкретном языке: списки окончаний для разных частей речи, разных склонений и т.д."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.030752Z",
          "start_time": "2023-04-18T16:50:58.029232Z"
        },
        "id": "tUI4LkoUvTY4"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.snowball import SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.032674Z",
          "start_time": "2023-04-18T16:50:58.031151Z"
        },
        "id": "2KNIH7RpbR28"
      },
      "outputs": [],
      "source": [
        "tokenized_example = word_tokenize(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.036669Z",
          "start_time": "2023-04-18T16:50:58.033530Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDhsgmNsvTY5",
        "outputId": "e275667a-7faf-46a9-f1e0-41c6cc43a9cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "но не кажд хочет что-т исправля : (\n"
          ]
        }
      ],
      "source": [
        "stemmer = SnowballStemmer(\"russian\")\n",
        "stemmed_example = [stemmer.stem(w) for w in tokenized_example]\n",
        "print(\" \".join(stemmed_example))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9SEnYhhbR28"
      },
      "source": [
        "Для английского получится что-то такое."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.038780Z",
          "start_time": "2023-04-18T16:50:58.036341Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYdj8R20vTY5",
        "outputId": "431f7c3b-f09b-47d0-d86a-d53cb12d3eab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In my younger and more vulnerable years my father gave me some advice that I've been turning over in my mind ever since.\n",
            "\"Whenever you feel like criticizing any one,\" he told me, \"just remember that all the people in this world haven't had the advantages that you've had.\"\n",
            "==========\n",
            "['In', 'my', 'younger', 'and', 'more', 'vulnerable', 'years', 'my', 'father', 'gave', 'me', 'some', 'advice', 'that', 'I', 'been', 'turning', 'over', 'in', 'my', 'mind', 'ever', 'since', 'Whenever', 'you', 'feel', 'like', 'criticizing', 'any', 'one', 'he', 'told', 'me', 'just', 'remember', 'that', 'all', 'the', 'people', 'in', 'this', 'world', 'have', 'had', 'the', 'advantages', 'that', 'you', 'had']\n"
          ]
        }
      ],
      "source": [
        "text = 'In my younger and more vulnerable years my father gave me some advice that I\\'ve been turning over in my mind ever since.\\n\"Whenever you feel like criticizing any one,\" he told me, \"just remember that all the people in this world haven\\'t had the advantages that you\\'ve had.\"'\n",
        "print(text)\n",
        "text_tokenized = [w for w in word_tokenize(text) if w.isalpha()]\n",
        "print(\"==========\")\n",
        "print(text_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.040805Z",
          "start_time": "2023-04-18T16:50:58.038614Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "386kIQJYvTY5",
        "outputId": "98c5b4c9-9be6-46bb-e440-819bd96c5df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in my younger and more vulner year my father gave me some advic that i been turn over in my mind ever sinc whenev you feel like critic ani one he told me just rememb that all the peopl in this world have had the advantag that you had\n"
          ]
        }
      ],
      "source": [
        "stemmer = SnowballStemmer(\"english\")\n",
        "text_stemmed = [stemmer.stem(w) for w in text_tokenized]\n",
        "print(\" \".join(text_stemmed))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5dNFUPHvTY6"
      },
      "source": [
        "## 4. Bag-of-words и TF-IDF\n",
        "\n",
        "Но как же все-таки работать с текстами, используя стандартные методы машинного обучения? Ведь нам нужны объекты выборки, которые описываются числами, а не словами. Иначе говоря, нам нужно *векторизовать* текстовые данные.\n",
        "\n",
        "### 4.1 Bag-of-words\n",
        "\n",
        "Пусть у нас имеется коллекция текстов $D = \\{d_i\\}_{i=1}^l$ и словарь всех слов, встречающихся в выборке $V = \\{v_j\\}_{j=1}^d.$ В этом случае некоторый текст $d_i$ описывается вектором $(x_{ij})_{j=1}^d,$ где\n",
        "$$x_{ij} = \\sum_{v \\in d_i} [v = v_j].$$\n",
        "\n",
        "Таким образом, текст $d_i$ описывается вектором количества вхождений каждого слова из словаря в данный текст."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.095188Z",
          "start_time": "2023-04-18T16:50:58.040839Z"
        },
        "id": "x2eF8nZLvTY7"
      },
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"I like my cat.\",\n",
        "    \"My cat is the most perfect cat.\",\n",
        "    \"is this cat or is this bread?\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.104626Z",
          "start_time": "2023-04-18T16:50:58.043952Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjG4gU5JvTY7",
        "outputId": "d56f4039-e8b3-4f3d-c21a-34562633be03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I like my cat',\n",
              " 'My cat is the most perfect cat',\n",
              " 'is this cat or is this bread']"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "texts_tokenized = [\n",
        "    \" \".join([w for w in word_tokenize(t) if w.isalpha()]) for t in texts\n",
        "]\n",
        "texts_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.104770Z",
          "start_time": "2023-04-18T16:50:58.046474Z"
        },
        "id": "NVomQglIvTY8"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cnt_vec = CountVectorizer()\n",
        "X = cnt_vec.fit_transform(texts_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.104925Z",
          "start_time": "2023-04-18T16:50:58.049174Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwAKWt_4vTY9",
        "outputId": "3e193939-3da9-4a5c-ef87-a4247a6d37dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['like', 'my', 'cat', 'is', 'the', 'most', 'perfect', 'this', 'or', 'bread'])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "cnt_vec.vocabulary_.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.105067Z",
          "start_time": "2023-04-18T16:50:58.051691Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye63VKazvTY-",
        "outputId": "401b2975-1f5f-4f55-fd3f-5761a719d9b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3x10 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 14 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.105194Z",
          "start_time": "2023-04-18T16:50:58.054Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvYOzpALvTY-",
        "outputId": "bf2c0531-ad12-44d1-be94-9f056e55d036"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 1, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 2, 1, 0, 1, 1, 0, 1, 1, 0],\n",
              "       [1, 1, 2, 0, 0, 0, 1, 0, 0, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "X.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.105450Z",
          "start_time": "2023-04-18T16:50:58.056639Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "z40jdf5-vTY-",
        "outputId": "06ace432-dae5-4435-921a-1275855f8703"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   like  my  cat  is  the  most  perfect  this  or  bread\n",
              "0     0   1    0   1    0     1        0     0   0      0\n",
              "1     0   2    1   0    1     1        0     1   1      0\n",
              "2     1   1    2   0    0     0        1     0   0      2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26f4a6a2-78cc-436f-baa2-71e0b2e1505e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>like</th>\n",
              "      <th>my</th>\n",
              "      <th>cat</th>\n",
              "      <th>is</th>\n",
              "      <th>the</th>\n",
              "      <th>most</th>\n",
              "      <th>perfect</th>\n",
              "      <th>this</th>\n",
              "      <th>or</th>\n",
              "      <th>bread</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26f4a6a2-78cc-436f-baa2-71e0b2e1505e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-26f4a6a2-78cc-436f-baa2-71e0b2e1505e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-26f4a6a2-78cc-436f-baa2-71e0b2e1505e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "pd.DataFrame(X.toarray(), columns=cnt_vec.vocabulary_.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tZsL30hvTY-"
      },
      "source": [
        "### 4.2 TF-IDF\n",
        "\n",
        "Заметим, что если слово часто встречается в одном тексте, но почти не встречается в других, то оно получает для данного текста большой вес, ровно так же, как и слова, которые часто встречаются в каждом тексте. Для того чтобы разделять эти такие слова, можно использовать статистическую меру TF-IDF, характеризующую важность слова для конкретного текста. Для каждого слова из текста $d$ рассчитаем относительную частоту встречаемости в нем (Term Frequency):\n",
        "$$\n",
        "\\text{TF}(t, d) = \\frac{C(t | d)}{\\sum\\limits_{k \\in d}C(k | d)},\n",
        "$$\n",
        "где $C(t | d)$ - число вхождений слова $t$ в текст $d$.\n",
        "\n",
        "Также для каждого слова из текста $d$ рассчитаем обратную частоту встречаемости в корпусе текстов $D$ (Inverse Document Frequency):\n",
        "$$\n",
        "\\text{IDF}(t, D) = \\log\\left(\\frac{|D|}{|\\{d_i \\in D \\mid t \\in d_i\\}|}\\right)\n",
        "$$\n",
        "Логарифмирование здесь проводится с целью уменьшить масштаб весов, ибо зачастую в корпусах присутствует очень много текстов.\n",
        "\n",
        "В итоге каждому слову $t$ из текста $d$ теперь можно присвоить вес\n",
        "$$\n",
        "\\text{TF-IDF}(t, d, D) = \\text{TF}(t, d) \\times \\text{IDF}(t, D)\n",
        "$$\n",
        "Интерпретировать формулу выше несложно: действительно, чем чаще данное слово встречается в данном тексте и чем реже в остальных, тем важнее оно для этого текста.\n",
        "\n",
        "Отметим, что в качестве TF и IDF можно использовать другие [определения](https://en.wikipedia.org/wiki/Tf%E2%80%93idf#Definition)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.105509Z",
          "start_time": "2023-04-18T16:50:58.061637Z"
        },
        "id": "F0YcEWeqvTY_"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vec = TfidfVectorizer()\n",
        "X = tfidf_vec.fit_transform(texts_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.105598Z",
          "start_time": "2023-04-18T16:50:58.064598Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpCVQJG8vTY_",
        "outputId": "d7a6f6e5-9a10-4133-c23e-7ab98e77fbaf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['like', 'my', 'cat', 'is', 'the', 'most', 'perfect', 'this', 'or', 'bread'])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "tfidf_vec.vocabulary_.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.105710Z",
          "start_time": "2023-04-18T16:50:58.066937Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saJG0dWyvTZA",
        "outputId": "3ea10b2e-361c-461a-f1d5-59a7719d6ccd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3x10 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 14 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.105840Z",
          "start_time": "2023-04-18T16:50:58.073856Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t43byRVIvTZA",
        "outputId": "6ff59e33-b916-46eb-eec2-dd82e29b2c55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.42544054, 0.        , 0.72033345, 0.        ,\n",
              "        0.54783215, 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.50130994, 0.32276391, 0.        , 0.42439575,\n",
              "        0.32276391, 0.        , 0.42439575, 0.42439575, 0.        ],\n",
              "       [0.33976626, 0.20067143, 0.516802  , 0.        , 0.        ,\n",
              "        0.        , 0.33976626, 0.        , 0.        , 0.67953252]])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "X.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.106645Z",
          "start_time": "2023-04-18T16:50:58.078284Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "YGpSpl4KvTZA",
        "outputId": "a404243a-142a-43c3-bbcb-268e621b2f3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       like        my       cat        is       the      most   perfect  \\\n",
              "0  0.000000  0.425441  0.000000  0.720333  0.000000  0.547832  0.000000   \n",
              "1  0.000000  0.501310  0.322764  0.000000  0.424396  0.322764  0.000000   \n",
              "2  0.339766  0.200671  0.516802  0.000000  0.000000  0.000000  0.339766   \n",
              "\n",
              "       this        or     bread  \n",
              "0  0.000000  0.000000  0.000000  \n",
              "1  0.424396  0.424396  0.000000  \n",
              "2  0.000000  0.000000  0.679533  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5dca493d-b6a8-42e6-ad64-e19c5b8591f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>like</th>\n",
              "      <th>my</th>\n",
              "      <th>cat</th>\n",
              "      <th>is</th>\n",
              "      <th>the</th>\n",
              "      <th>most</th>\n",
              "      <th>perfect</th>\n",
              "      <th>this</th>\n",
              "      <th>or</th>\n",
              "      <th>bread</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.425441</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.720333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.547832</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.501310</td>\n",
              "      <td>0.322764</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.424396</td>\n",
              "      <td>0.322764</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.424396</td>\n",
              "      <td>0.424396</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.339766</td>\n",
              "      <td>0.200671</td>\n",
              "      <td>0.516802</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.339766</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.679533</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dca493d-b6a8-42e6-ad64-e19c5b8591f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5dca493d-b6a8-42e6-ad64-e19c5b8591f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5dca493d-b6a8-42e6-ad64-e19c5b8591f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "pd.DataFrame(X.toarray(), columns=tfidf_vec.vocabulary_.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwcgx05UvTZA"
      },
      "source": [
        "**Вопросик:** что изменилось по сравнению с использованием метода `CountVectorizer`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrP93rWwvTZB"
      },
      "source": [
        "## 5. Решение задачи с текстовыми данными\n",
        "\n",
        "Будем решать задачу классификации твитов по тональности. Возьмём датасет из твитов, в котором про каждый твит известно, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску. Классификацию по тональности используют, например, в рекомендательных системах, чтобы понять, понравилось ли людям кафе, кино, etc.\n",
        "\n",
        "Скачиваем куски датасета ([источник](http://study.mokoron.com/)): [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.106702Z",
          "start_time": "2023-04-18T16:50:58.080790Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWF6vuvTbR2_",
        "outputId": "998f189c-4441-43ee-d68c-c43b2fcc434c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-14 08:12:52--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n",
            "--2023-08-14 08:12:53--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 429 Too Many Requests\n",
            "2023-08-14 08:12:53 ERROR 429: Too Many Requests.\n",
            "\n",
            "--2023-08-14 08:12:53--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n",
            "--2023-08-14 08:12:53--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 429 Too Many Requests\n",
            "2023-08-14 08:12:53 ERROR 429: Too Many Requests.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# если у вас линукс / мак / collab или ещё какая-то среда, в которой работает wget, можно так:\n",
        "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
        "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.106741Z",
          "start_time": "2023-04-18T16:50:58.082275Z"
        },
        "id": "R6Kj2UDCbR2_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MaxAbsScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.494315Z",
          "start_time": "2023-04-18T16:50:58.085576Z"
        },
        "id": "klHlDntAbR2_"
      },
      "outputs": [],
      "source": [
        "# считываем данные и заполняем общий датасет\n",
        "positive = pd.read_csv(\"positive.csv\", sep=\";\", usecols=[3], names=[\"text\"])\n",
        "positive[\"label\"] = \"positive\"\n",
        "negative = pd.read_csv(\"negative.csv\", sep=\";\", usecols=[3], names=[\"text\"])\n",
        "negative[\"label\"] = \"negative\"\n",
        "df = pd.concat([positive, negative])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive.to_csv(\"positive_tweets.csv\", index=False)\n",
        "negative.to_csv(\"negative_tweets.csv\", index=False)"
      ],
      "metadata": {
        "id": "lYULeJqRIFJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.498928Z",
          "start_time": "2023-04-18T16:50:58.495906Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "NOx1D6mFbR2_",
        "outputId": "a57fdc9c-e7bd-45e0-a09f-6fcd95ea5990"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text     label\n",
              "114906  Спала в родительском доме, на своей кровати......  positive\n",
              "114907  RT @jebesilofyt: Эх... Мы немного решили сокра...  positive\n",
              "114908  Что происходит со мной, когда в эфире #proacti...  positive\n",
              "114909  \"Любимая,я подарю тебе эту звезду...\" Имя како...  positive\n",
              "114910  @Ma_che_rie посмотри #непытайтесьпокинутьомск ...  positive"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-68f24b19-46e7-4f5e-a2e2-2dda542c8295\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>114906</th>\n",
              "      <td>Спала в родительском доме, на своей кровати......</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114907</th>\n",
              "      <td>RT @jebesilofyt: Эх... Мы немного решили сокра...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114908</th>\n",
              "      <td>Что происходит со мной, когда в эфире #proacti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114909</th>\n",
              "      <td>\"Любимая,я подарю тебе эту звезду...\" Имя како...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114910</th>\n",
              "      <td>@Ma_che_rie посмотри #непытайтесьпокинутьомск ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68f24b19-46e7-4f5e-a2e2-2dda542c8295')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-d09a0850-1be0-4723-91fa-8154bb134365\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d09a0850-1be0-4723-91fa-8154bb134365')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-d09a0850-1be0-4723-91fa-8154bb134365 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68f24b19-46e7-4f5e-a2e2-2dda542c8295 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68f24b19-46e7-4f5e-a2e2-2dda542c8295');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.501134Z",
          "start_time": "2023-04-18T16:50:58.498598Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsDtXDT6bR3A",
        "outputId": "0c57d827-0708-4b37-dab6-b0e905dbbe52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(226834, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.534375Z",
          "start_time": "2023-04-18T16:50:58.501394Z"
        },
        "id": "Hl6lpWBcbR3A"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label, random_state=13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfTm_-3sbR3A"
      },
      "source": [
        "#### n-граммы\n",
        "\n",
        "n-граммы — это последовательности n токенов из исходного текста. В простейшем случае это могут быть последовательности из букв или последовательности из слов. Давайте посмотрим подробнее на примере."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.535017Z",
          "start_time": "2023-04-18T16:50:58.516459Z"
        },
        "id": "mMoCnsi5vTZB"
      },
      "outputs": [],
      "source": [
        "from nltk import ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.555122Z",
          "start_time": "2023-04-18T16:50:58.518609Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIf_da6RvTZD",
        "outputId": "db5dca1e-aa9a-42aa-cecc-e700968c47c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "sent = \"Если б мне платили каждый раз\".split()\n",
        "list(ngrams(sent, 1))  # униграммы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.555317Z",
          "start_time": "2023-04-18T16:50:58.521205Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhaYTVyuvTZD",
        "outputId": "163aef0e-04f8-498a-a58f-0ba98ec849ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б'),\n",
              " ('б', 'мне'),\n",
              " ('мне', 'платили'),\n",
              " ('платили', 'каждый'),\n",
              " ('каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "list(ngrams(sent, 2))  # биграммы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.555416Z",
          "start_time": "2023-04-18T16:50:58.523529Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fpat_ZGvTZD",
        "outputId": "00dc7893-74d9-4c4f-a5ec-a964e59a240e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б', 'мне'),\n",
              " ('б', 'мне', 'платили'),\n",
              " ('мне', 'платили', 'каждый'),\n",
              " ('платили', 'каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "list(ngrams(sent, 3))  # триграммы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:50:58.555533Z",
          "start_time": "2023-04-18T16:50:58.525914Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK2QdeycvTZE",
        "outputId": "d8380bd3-4b3f-4f9c-a3df-b1d144537ccd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
              " ('б', 'мне', 'платили', 'каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "list(ngrams(sent, 5))  # ... пентаграммы?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t51hgE52bR3A"
      },
      "source": [
        "В качестве альтернативы можно пользоваться `CountVectorizer`, который работает так:\n",
        "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности количества токенов в нашем словаре\n",
        "* заполняет каждый i-тый элемент количеством вхождений токена в данный документ\n",
        "\n",
        "Параметр `ngram_range` отвечает за то, какие n-граммы мы используем в качестве фичей:\n",
        "- `ngram_range=(1, 1)` — униграммы\n",
        "- `ngram_range=(3, 3)` — триграммы\n",
        "- `ngram_range=(1, 3)` — униграммы, биграммы и триграммы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRoCBw4sbR3B"
      },
      "source": [
        "### 5.1 Обучение моделей\n",
        "\n",
        "Давайте обучим наш первый бейзлайн — логрег на униграммах!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:51:05.699896Z",
          "start_time": "2023-04-18T16:50:58.589759Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFQV-aUlbR3B",
        "outputId": "825db3ca-2b27-468f-8376-38527de3e923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.76      0.77      0.76     27957\n",
            "    positive       0.77      0.76      0.77     28752\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(x_train)  # bow — bag of words (мешок слов)\n",
        "bow_test = vec.transform(x_test)\n",
        "\n",
        "scaler = MaxAbsScaler()\n",
        "bow = scaler.fit_transform(bow)\n",
        "bow_test = scaler.transform(bow_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=200, random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(bow_test)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a56F0vivTZL"
      },
      "source": [
        "Попробуем сделать то же самое для триграмм."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:51:32.529458Z",
          "start_time": "2023-04-18T16:51:05.755811Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3GF-cDvbR3B",
        "outputId": "77dac55f-5ebb-4794-c344-2a094d086444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.72      0.47      0.57     27957\n",
            "    positive       0.61      0.82      0.70     28752\n",
            "\n",
            "    accuracy                           0.65     56709\n",
            "   macro avg       0.67      0.65      0.64     56709\n",
            "weighted avg       0.67      0.65      0.64     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = CountVectorizer(ngram_range=(3, 3))\n",
        "bow = vec.fit_transform(x_train)\n",
        "bow_test = vec.transform(x_test)\n",
        "\n",
        "scaler = MaxAbsScaler()\n",
        "bow = scaler.fit_transform(bow)\n",
        "bow_test = scaler.transform(bow_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=200, random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred_thrgramm = clf.predict(bow_test)\n",
        "print(classification_report(y_test, pred_thrgramm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySP1M-nJbR3B"
      },
      "source": [
        "В нашем случае стало хуже :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyW9lA_6vTZL"
      },
      "source": [
        "А теперь повторим процедуру для TF-IDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:51:40.397191Z",
          "start_time": "2023-04-18T16:51:32.587689Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RWk5BFqbR3B",
        "outputId": "99a99859-8eed-4c2e-8c08-0e321913950d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.77      0.75      0.76     27957\n",
            "    positive       0.76      0.78      0.77     28752\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
        "vec_train = vec.fit_transform(x_train)\n",
        "vec_test = vec.transform(x_test)\n",
        "\n",
        "scaler = MaxAbsScaler()\n",
        "vec_train = scaler.fit_transform(vec_train)\n",
        "vec_test = scaler.transform(vec_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=300, random_state=42)\n",
        "clf.fit(vec_train, y_train)\n",
        "pred_tfidf = clf.predict(vec_test)\n",
        "print(classification_report(y_test, pred_tfidf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixapx51FvTZM"
      },
      "source": [
        "### 5.2 О важности эксплоративного анализа\n",
        "\n",
        "Но иногда пунктуация бывает и не шумом. Главное — отталкиваться от задачи. Что будет если вообще не убирать пунктуацию?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:52:00.862268Z",
          "start_time": "2023-04-18T16:51:40.411317Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gifDKaj9bR3B",
        "outputId": "68e9d78f-698c-4ffa-fc6f-97443c297969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.95      0.97      0.96     27957\n",
            "    positive       0.97      0.95      0.96     28752\n",
            "\n",
            "    accuracy                           0.96     56709\n",
            "   macro avg       0.96      0.96      0.96     56709\n",
            "weighted avg       0.96      0.96      0.96     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
        "bow = vec.fit_transform(x_train)\n",
        "bow_test = vec.transform(x_test)\n",
        "\n",
        "scaler = MaxAbsScaler()\n",
        "bow = scaler.fit_transform(bow)\n",
        "bow_test = scaler.transform(bow_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=200, random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(bow_test)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_8uz4TevTZM"
      },
      "source": [
        "Стоило оставить пунктуацию, и внезапно все метрики устремились к 1. Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдём признак с самыми большим коэффициентом:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:52:00.881501Z",
          "start_time": "2023-04-18T16:52:00.879232Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "sub0KWQ-bR3C",
        "outputId": "fd71ae7e-7e9b-4de9-e1d9-792159fc72c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "')'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "reverse_vocab = {value: key for key, value in vec.vocabulary_.items()}\n",
        "reverse_vocab[np.argmax(clf.coef_)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZC8Mb6bvTZM"
      },
      "source": [
        "Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:52:01.743208Z",
          "start_time": "2023-04-18T16:52:00.882081Z"
        },
        "id": "vvWdQbYMvTZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae9b0aad-c833-48a7-cfe3-90f9172724b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      1.00      0.92     27957\n",
            "    positive       1.00      0.83      0.91     28752\n",
            "\n",
            "    accuracy                           0.91     56709\n",
            "   macro avg       0.93      0.92      0.91     56709\n",
            "weighted avg       0.93      0.91      0.91     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cool_token = reverse_vocab[np.argmax(clf.coef_)]\n",
        "pred = [\"positive\" if cool_token in tweet else \"negative\" for tweet in x_test]\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:52:01.799440Z",
          "start_time": "2023-04-18T16:52:01.743612Z"
        },
        "id": "3nD71B-ZvTZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "201827ea-9248-4811-de2b-17a6947097cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "“@Fashionbar_uz: Ladies Monday . Каждый понедельник для всех девушек кальяны от заведения. #fashionbar http://t.co/ZlvxOcZPR4” zaviduyu))\n",
            "Гримерка-лук))) #evabristol #performance #gig #vocaldiva #гастроли #гитис #театр http://t.co/S60OvyyTS6\n",
            "RT @alivfedorov: http://t.co/DvYLJaPHxR Девушки это самые хитрые создания! так что даже не пытайся их обмануть!:)\n",
            "@pavelsheremet @ukrpravda_news @varlamov хотя исторически правильно желто-синий:)\n",
            "Понятия не имею чем меня привлекла эта картинка!)))http://t.co/twqP8zyh1A\n",
            "@Sveta12126 ну или пусть Лиама пришлет ко мне) своего младшенького. Как сказала Кэтрин: \"Это нормально - любить двоих\" ахах\n",
            "Вышел в свет новый каталог запасных частей и деталей ТМК! Звоните - подарим :)\n",
            "@u_alekseeva_17 видужуй:3\n",
            "Я там тепер буду кожну середу)\n",
            "29-й выпуск Дроидкаста будет не против ваших плюсов на Хабре   ;)\n",
            "@nemoniga а я вот знаю :) нам на политической географии рассказывал душечка Гурин\n"
          ]
        }
      ],
      "source": [
        "cool_token = reverse_vocab[np.argmax(clf.coef_)]\n",
        "tweets_with_cool_token = [tweet for tweet in x_train if cool_token in tweet]\n",
        "np.random.seed(42)\n",
        "for tweet in np.random.choice(tweets_with_cool_token, size=10, replace=False):\n",
        "    print(tweet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv6P8ncIvTZO"
      },
      "source": [
        "### 5.3 Символьные n-граммы\n",
        "\n",
        "Теперь в качестве признаков используем, например, униграммы символов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:52:07.747526Z",
          "start_time": "2023-04-18T16:52:01.811832Z"
        },
        "id": "TvvJiY3pbR3C",
        "outputId": "e0efee68-1070-449d-d3de-e9a146d32fd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.99      0.97      0.98     27957\n",
            "    positive       0.98      0.99      0.98     28752\n",
            "\n",
            "    accuracy                           0.98     56709\n",
            "   macro avg       0.98      0.98      0.98     56709\n",
            "weighted avg       0.98      0.98      0.98     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 1), analyzer=\"char\")\n",
        "bow = vec.fit_transform(x_train)\n",
        "bow_test = vec.transform(x_test)\n",
        "\n",
        "scaler = MaxAbsScaler()\n",
        "bow = scaler.fit_transform(bow)\n",
        "bow_test = scaler.transform(bow_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=200, random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(bow_test)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PK8-_xwvTZO"
      },
      "source": [
        "В общем-то, теперь уже понятно, почему на этих данных здесь 1. Так или иначе, на символах классифицировать тоже можно: для некоторых задач (например, для определения языка) признаки-символьные n-граммы могут внести серьезный вклад в качество модели. Ещё одна замечательная особенность признаков-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готовых анализаторов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "islq37BzvTZP"
      },
      "source": [
        "## 6. Регулярные выражения\n",
        "\n",
        "Вообще, часто бывает так, что для конкретного случая нужен особый способ токенизации, и надо самостоятельно написать правило шаблонного типа для определения того, что такое токен. Или, например, перед работой с текстом, надо почистить его от своеобразного мусора: упоминаний пользователей, url и так далее. В таких задачах могут помочь регулярные выражения. Навык полезный, давайте в нём тоже потренируемся."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:52:07.749061Z",
          "start_time": "2023-04-18T16:52:07.747327Z"
        },
        "id": "ymGN9r6gvTZP"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qJxZd2pvTZQ"
      },
      "source": [
        "### findall\n",
        "возвращает список всех найденных совпадений\n",
        "\n",
        "- ? : ноль или одно повторение\n",
        "- \\* : ноль или более повторений\n",
        "- \\+ : одно или более повторений\n",
        "- . : любой символ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:52:07.751928Z",
          "start_time": "2023-04-18T16:52:07.749921Z"
        },
        "id": "Hn6AnrvtvTZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51b16c8c-573b-4659-feac-d349a53bae2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abcd', 'abca']\n"
          ]
        }
      ],
      "source": [
        "result = re.findall(\"ab+c.\", \"abcdefghijkabcabcxabc\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHOTT9XTvTZQ"
      },
      "source": [
        "Вопрос на внимательность: почему нет abcx?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:52:07.754693Z",
          "start_time": "2023-04-18T16:52:07.751977Z"
        },
        "id": "k7gzrPCOvTZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d1e31b-6f89-4cee-8145-22da882466d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abbbca']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "re.findall(\"ab+c.\", \"abbbca\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qxi1znlvTZR"
      },
      "source": [
        "### split\n",
        "разделяет строку по заданному шаблону\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:52:07.756104Z",
          "start_time": "2023-04-18T16:52:07.754642Z"
        },
        "id": "z3Qz-3RSvTZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0904328a-ee33-4a33-b50d-8106a2912b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['itsy', ' bitsy', ' teenie', ' weenie']\n"
          ]
        }
      ],
      "source": [
        "result = re.split(\",\", \"itsy, bitsy, teenie, weenie\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ur6WK3GvTZR"
      },
      "source": [
        "можно указать максимальное количество разбиений"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:52:07.758646Z",
          "start_time": "2023-04-18T16:52:07.756699Z"
        },
        "id": "Pwu8L0LevTZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c448cfe2-7199-4313-b32a-4041a9bf6030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['itsy', ' bitsy', ' teenie, weenie']\n"
          ]
        }
      ],
      "source": [
        "result = re.split(\",\", \"itsy, bitsy, teenie, weenie\", maxsplit=2)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGFk3MpOvTZS"
      },
      "source": [
        "### sub\n",
        "ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n",
        "\n",
        "параметры: (pattern, repl, string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:52:07.760056Z",
          "start_time": "2023-04-18T16:52:07.758723Z"
        },
        "id": "azeAmGOBvTZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc42567d-09fd-4045-c206-2f7ca0a057d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bbcbbc\n"
          ]
        }
      ],
      "source": [
        "result = re.sub(\"a\", \"b\", \"abcabc\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZPyd-2gbR3D"
      },
      "source": [
        "При этом в качестве repl, можно передавать не только строку, но и функцию, которая принимает на вход [Match](https://docs.python.org/3/library/re.html#match-objects) объект. Можно делать что-то типа этого:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:52:07.762722Z",
          "start_time": "2023-04-18T16:52:07.761009Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "da_y-XHpbR3E",
        "outputId": "63963fd5-2037-4b97-d11a-6b0052d0f2f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(a#1)bc(a#2)bc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "counter = 0\n",
        "\n",
        "def count(match):\n",
        "    global counter\n",
        "    counter += 1\n",
        "    return f\"(a#{counter})\"\n",
        "\n",
        "\n",
        "re.sub(\"a\", count, \"abcabc\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKQFFuzpbR3E"
      },
      "source": [
        "Кстати, c объектами типа re.Match работают и многие другие методы re. Например, метод re.finditer в отличии от re.findall будет возвращать те самые re.Match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:52:07.765456Z",
          "start_time": "2023-04-18T16:52:07.763298Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0GKlxBebR3E",
        "outputId": "bf2c9eb9-d0e9-475e-ee4b-d6b7029b4874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 4), match='abcd'>\n",
            "<re.Match object; span=(11, 15), match='abca'>\n"
          ]
        }
      ],
      "source": [
        "for match in re.finditer(\"ab+c.\", \"abcdefghijkabcabcxabc\"):\n",
        "    print(match)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi1Br-53bR3E"
      },
      "source": [
        "Помимо найденных строчек объекты Match также, например, содержат информацию о позиции найденного \"совпадения\" в строке (span)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY8kwgOVvTZS"
      },
      "source": [
        "### compile\n",
        "компилирует регулярное выражение в отдельный объект"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:52:07.859382Z",
          "start_time": "2023-04-18T16:52:07.765680Z"
        },
        "id": "Nudrx7nJvTZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19e13c4-269c-4c56-abf8-6d2e8167db54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Слова', 'Да', 'больше', 'ещё', 'больше', 'слов', 'Что-то', 'ещё']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "# Пример: построение списка всех слов строки:\n",
        "\n",
        "prog = re.compile(\"[А-Яа-яё\\-]+\")\n",
        "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YONOWD3XvTZS"
      },
      "source": [
        "**Задание**: вернуть список доменов (@gmail.com) из списка адресов электронной почты:\n",
        "\n",
        "```\n",
        "abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:52:07.859551Z",
          "start_time": "2023-04-18T16:52:07.768184Z"
        },
        "id": "JLWpguIsvTZT"
      },
      "outputs": [],
      "source": [
        "emails = \"abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-18T16:52:07.860119Z",
          "start_time": "2023-04-18T16:52:07.770050Z"
        },
        "id": "ayTzy2lCvTZT"
      },
      "outputs": [],
      "source": [
        "# <YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Бонус: классный сайт с регулярками:\n",
        "https://regex101.com/"
      ],
      "metadata": {
        "id": "ow5ol1glgAWv"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}